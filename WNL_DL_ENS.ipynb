{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 21:01:06.903434: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 21:01:06.984261: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-03 21:01:07.487896: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-03 21:01:07.487936: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-03 21:01:07.487941: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections.abc import Iterable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import time\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define gvars\n",
    "SEED = 1080\n",
    "VCHUNK = 64\n",
    "NUM_CLASSES = 12\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SPLIT = 0.2\n",
    "EPOCHS = 50\n",
    "LR = 0.001\n",
    "METRIC = 'val_accuracy'\n",
    "MIN_DELTA = 1e-4\n",
    "PATIENCE = 100\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# import from csv to dataframe\n",
    "df = pd.read_csv('wnl/WNL_TLS_Dataset_ECH.csv', sep='\\t')\n",
    "esni = pd.read_csv('wnl/WNL_TLS_Dataset_ESNI.csv', sep='\\t')\n",
    "\n",
    "# set checkpoint path and filename\n",
    "check_name = \"WNL_CLASS_ENS.chkp\"\n",
    "check_path = \"checkpoint/\" + check_name\n",
    "\n",
    "# define our callbacks\n",
    "callbacks = [\n",
    "\n",
    "    # define checkpoint callback\n",
    "    tf.keras.callbacks.ModelCheckpoint (\n",
    "        check_path,\n",
    "        monitor= 'val_accuracy',\n",
    "        verbose= 1,\n",
    "        save_best_only= True,\n",
    "        save_weights_only= True,\n",
    "        mode= 'auto',\n",
    "        save_freq='epoch',\n",
    "        options=None,\n",
    "        initial_value_threshold=THRESHOLD,\n",
    "    ),\n",
    "\n",
    "    # # define early stopping callback\n",
    "    # tf.keras.callbacks.EarlyStopping(\n",
    "    #     monitor=METRIC,\n",
    "    #     min_delta=MIN_DELTA,\n",
    "    #     patience=PATIENCE,\n",
    "    #     verbose=1\n",
    "    # ),\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''https://tls13.xargs.org/#client-hello/annotated'''\n",
    "\n",
    "def flatten(L):\n",
    "    '''flattens a list of nested list of arbitrary depth into a single concatenated list'''\n",
    "    for x in L:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n",
    "            yield from flatten(x)\n",
    "        else:\n",
    "            yield x\n",
    "\n",
    "def padding(A, size):\n",
    "    '''pads a given list to a given length'''\n",
    "    t = size - len(A)\n",
    "\n",
    "    return np.pad(A, pad_width=(0, t), mode='constant')\n",
    "\n",
    "def parse_CHP(p):\n",
    "    '''\n",
    "    implements the Shamsimukhametov et al. bytes recomposition algorithm\n",
    "    builds a fixed length feature vector from clienthello message\n",
    "    '''\n",
    "    T = []\n",
    "    L = []\n",
    "    V = []\n",
    "\n",
    "    handshake_len = sum(p[3:5])\n",
    "    clienthello_len = sum(p[6:9])\n",
    "    sid_len = p[43]\n",
    "    i = 44+sid_len\n",
    "\n",
    "    sid = p[44:i]\n",
    "    ciphersuite_len = sum(p[i:i+2])\n",
    "    ciphersuite = p[i+2:i+2+ciphersuite_len]\n",
    "    i += 4 + ciphersuite_len\n",
    "\n",
    "    ext_len = sum(p[i:i+2])\n",
    "    i = i+2\n",
    "    \n",
    "    T.append(padding(sid, 32))\n",
    "    L.append(handshake_len)\n",
    "    L.append(clienthello_len)\n",
    "    L.append(sid_len)\n",
    "    L.append(ciphersuite_len)\n",
    "    L.append(ext_len)\n",
    "    V.append(ciphersuite)\n",
    "    \n",
    "    end = i + ext_len\n",
    "    count = 0   \n",
    "\n",
    "    while (i < len(p)):\n",
    "\n",
    "        n_ext_id = sum(p[i:i+2])\n",
    "        i+=2\n",
    "        \n",
    "        n_ext_len = sum(p[i:i+2])\n",
    "        i+=2\n",
    "\n",
    "        T.append(n_ext_id)\n",
    "        L.append(n_ext_len)\n",
    "        V.append(p[i:i+n_ext_len])\n",
    "        i+=n_ext_len\n",
    "\n",
    "    T = padding(list(flatten(T)),40)\n",
    "    L = padding(list(flatten(L)),13)\n",
    "    V = list(flatten(V))\n",
    "    VC = V[:VCHUNK]\n",
    "\n",
    "    return np.concatenate((T,L,VC))\n",
    "\n",
    "def parse_SHP(p):\n",
    "    '''\n",
    "    implements the Shamsimukhametov et al. bytes recomposition algorithm\n",
    "    builds a fixed length feature vector from serverhello message\n",
    "    '''\n",
    "    T = []\n",
    "    L = []\n",
    "    V = []\n",
    "\n",
    "    handshake_len = sum(p[3:5])\n",
    "    serverhello_len = sum(p[6:9])\n",
    "    sid_len = p[43]\n",
    "    i = 44+sid_len\n",
    "\n",
    "    sid = p[44:i]\n",
    "    ciphersuite = sum(p[i:i+2])\n",
    "    i += 3\n",
    "\n",
    "    ext_len = sum(p[i:i+2])\n",
    "    i = i+2\n",
    "    \n",
    "    T.append(padding(sid, 32))\n",
    "    T.append(ciphersuite)\n",
    "    L.append(handshake_len)\n",
    "    L.append(serverhello_len)\n",
    "    L.append(sid_len)\n",
    "    L.append(ext_len)\n",
    "\n",
    "    end = i + ext_len\n",
    "    count = 0    \n",
    "    \n",
    "    while (i < len(p)):\n",
    "\n",
    "        n_ext_id = sum(p[i:i+2])\n",
    "        i+=2\n",
    "        \n",
    "        n_ext_len = sum(p[i:i+2])\n",
    "        i+=2\n",
    "\n",
    "        T.append(n_ext_id)\n",
    "        L.append(n_ext_len)\n",
    "        V.append(p[i:i+n_ext_len])\n",
    "        i+=n_ext_len\n",
    "\n",
    "    T = padding(list(flatten(T)),40)\n",
    "    L = padding(list(flatten(L)),10)\n",
    "    V = list(flatten(V))\n",
    "    VC = V[:VCHUNK]\n",
    "\n",
    "    return np.concatenate((T,L,VC))\n",
    "\n",
    "def parse_payload(CH,SH):\n",
    "    '''builds a concatenated fixed length feature vector of recomposed bytes'''\n",
    "    chp  = np.fromstring(CH, dtype=int, sep=',')\n",
    "    shp  = np.fromstring(SH, dtype=int, sep=',')\n",
    "    chv = parse_CHP(chp)\n",
    "    shv = parse_SHP(shp)\n",
    "    return np.concatenate((chv,shv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform according to recomposition algorithm\n",
    "df['X'] = df.apply(lambda row : parse_payload(row['ClientHello'], row['ServerHello']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode classes into integers as terget variable vector y\n",
    "labels = df.Label.unique()\n",
    "df['Label'] = df['Label'].astype('category')\n",
    "df['target'] = df['Label'].cat.codes\n",
    "y = df['target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand array to proper dims\n",
    "dfx = pd.DataFrame(df['X'].tolist()).add_prefix(\"x\")\n",
    "X = dfx.to_numpy(dtype=np.int16)\n",
    "X = X/256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Leak Check\n",
      "2792\n",
      "349\n",
      "349\n",
      "2792 2792 698 698 349 349 349 349\n",
      "231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 21:01:09.047884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 21:01:09.066770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 21:01:09.066911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 21:01:09.067307: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 21:01:09.067766: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 21:01:09.067856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 21:01:09.067930: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 21:01:09.427384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 21:01:09.427567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 21:01:09.427650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 21:01:09.427720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 463 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the training data into train and val_test sets using categorical stratification\n",
    "X_train, X_val_test, y_train , y_val_test = train_test_split(   X,\n",
    "                                                                y,\n",
    "                                                                stratify=y,\n",
    "                                                                shuffle=True,\n",
    "                                                                test_size=SPLIT,\n",
    "                                                                random_state=SEED\n",
    "                                                                )\n",
    "\n",
    "# split the val_test data into val and test sets using categorical stratification\n",
    "X_val, X_test, y_val , y_test = train_test_split(       X_val_test,\n",
    "                                                        y_val_test,\n",
    "                                                        test_size=0.5,\n",
    "                                                        random_state=SEED\n",
    "                                                        )\n",
    "# get sizes\n",
    "len_a = len(X_train)\n",
    "len_b = len(X_train[5])\n",
    "\n",
    "# reshape to fit the model\n",
    "X_train = tf.reshape(X_train,(len_a,len_b,1))\n",
    "\n",
    "# check for data leakage\n",
    "print('Data Leak Check')\n",
    "# need method to check for duplicate rows in data\n",
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))\n",
    "print(len(X_train), len(y_train), len(X_val_test), len(y_val_test), len(X_val), len(X_test), len(y_val), len(y_test)), print(len(X_train[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 231, 1)]          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 229, 256)          1024      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 229, 256)         1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 114, 256)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 114, 462)         677754    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 114, 462)         1848      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 57, 462)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 57, 462)          1282512   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 57, 462)          1848      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 28, 462)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 462)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 231)               106953    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 231)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                2784      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,075,747\n",
      "Trainable params: 2,073,387\n",
      "Non-trainable params: 2,360\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# compose the model architecture function\n",
    "def compose_model():\n",
    "    in_layer = layers.Input(shape=(len_b,1))\n",
    "    x = layers.Conv1D(256, 3, padding='valid', strides=1, activation=\"relu\", input_shape=(len_b,1))(in_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool1D()(x)\n",
    "\n",
    "    x = layers.Bidirectional(layers.GRU(len_b, return_sequences=True))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool1D()(x)\n",
    "\n",
    "    x = layers.Bidirectional(layers.LSTM(len_b, return_sequences=True))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool1D()(x)\n",
    " \n",
    "    # generic stacked dense softmax classifier\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dense(len_b, activation='relu')(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    out_layer = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    return Model(inputs=in_layer, outputs=out_layer)\n",
    "\n",
    "# instantiate the model\n",
    "model = compose_model()\n",
    "\n",
    "# load previously trained weights\n",
    "#status = model.load_weights(check_path).expect_partial()\n",
    "\n",
    "# inspect model stack\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 21:01:14.230114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700\n",
      "2023-04-03 21:01:14.655552: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-03 21:01:14.655574: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-03 21:01:14.791737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-04-03 21:01:14.792952: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f939558fc50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-03 21:01:14.792966: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2023-04-03 21:01:14.795929: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-03 21:01:14.873852: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/88 [=>............................] - ETA: 1s - loss: 3.9315 - accuracy: 0.1741    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 21:01:15.774159: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-03 21:01:15.774190: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - ETA: 0s - loss: 1.6897 - accuracy: 0.4703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 21:01:17.283602: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-03 21:01:17.283631: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-03 21:01:17.297916: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-03 21:01:17.297954: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.50000\n",
      "88/88 [==============================] - 8s 26ms/step - loss: 1.6897 - accuracy: 0.4703 - val_loss: 2.3398 - val_accuracy: 0.1605\n",
      "Epoch 2/50\n",
      "11/88 [==>...........................] - ETA: 1s - loss: 1.1278 - accuracy: 0.5625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 21:01:18.068789: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-04-03 21:01:18.068818: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/88 [===========================>..] - ETA: 0s - loss: 0.9611 - accuracy: 0.6430\n",
      "Epoch 2: val_accuracy did not improve from 0.50000\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.9580 - accuracy: 0.6443 - val_loss: 2.2446 - val_accuracy: 0.2464\n",
      "Epoch 3/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.7319 - accuracy: 0.7158\n",
      "Epoch 3: val_accuracy did not improve from 0.50000\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.7319 - accuracy: 0.7156 - val_loss: 1.9638 - val_accuracy: 0.2980\n",
      "Epoch 4/50\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.6593 - accuracy: 0.7500\n",
      "Epoch 4: val_accuracy did not improve from 0.50000\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.6589 - accuracy: 0.7504 - val_loss: 1.8858 - val_accuracy: 0.2951\n",
      "Epoch 5/50\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.5723 - accuracy: 0.7713\n",
      "Epoch 5: val_accuracy did not improve from 0.50000\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.5703 - accuracy: 0.7726 - val_loss: 1.4631 - val_accuracy: 0.3524\n",
      "Epoch 6/50\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.5364 - accuracy: 0.7838\n",
      "Epoch 6: val_accuracy did not improve from 0.50000\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.5371 - accuracy: 0.7833 - val_loss: 1.3317 - val_accuracy: 0.4642\n",
      "Epoch 7/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.4612 - accuracy: 0.8198\n",
      "Epoch 7: val_accuracy improved from 0.50000 to 0.72206, saving model to checkpoint/WNL_CLASS_ENS.chkp\n",
      "88/88 [==============================] - 2s 28ms/step - loss: 0.4603 - accuracy: 0.8206 - val_loss: 0.6150 - val_accuracy: 0.7221\n",
      "Epoch 8/50\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.4158 - accuracy: 0.8364\n",
      "Epoch 8: val_accuracy improved from 0.72206 to 0.76791, saving model to checkpoint/WNL_CLASS_ENS.chkp\n",
      "88/88 [==============================] - 2s 19ms/step - loss: 0.4158 - accuracy: 0.8360 - val_loss: 0.4866 - val_accuracy: 0.7679\n",
      "Epoch 9/50\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.3674 - accuracy: 0.8621\n",
      "Epoch 9: val_accuracy improved from 0.76791 to 0.86533, saving model to checkpoint/WNL_CLASS_ENS.chkp\n",
      "88/88 [==============================] - 2s 19ms/step - loss: 0.3696 - accuracy: 0.8589 - val_loss: 0.3123 - val_accuracy: 0.8653\n",
      "Epoch 10/50\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.3310 - accuracy: 0.8676\n",
      "Epoch 10: val_accuracy did not improve from 0.86533\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.3322 - accuracy: 0.8671 - val_loss: 0.3048 - val_accuracy: 0.8453\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.2932 - accuracy: 0.8761\n",
      "Epoch 11: val_accuracy improved from 0.86533 to 0.87393, saving model to checkpoint/WNL_CLASS_ENS.chkp\n",
      "88/88 [==============================] - 2s 26ms/step - loss: 0.2932 - accuracy: 0.8761 - val_loss: 0.2464 - val_accuracy: 0.8739\n",
      "Epoch 12/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.2966 - accuracy: 0.8725\n",
      "Epoch 12: val_accuracy did not improve from 0.87393\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2972 - accuracy: 0.8721 - val_loss: 0.2813 - val_accuracy: 0.8739\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.8872\n",
      "Epoch 13: val_accuracy did not improve from 0.87393\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2763 - accuracy: 0.8872 - val_loss: 0.2808 - val_accuracy: 0.8625\n",
      "Epoch 14/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.2686 - accuracy: 0.8870\n",
      "Epoch 14: val_accuracy improved from 0.87393 to 0.88825, saving model to checkpoint/WNL_CLASS_ENS.chkp\n",
      "88/88 [==============================] - 2s 19ms/step - loss: 0.2698 - accuracy: 0.8854 - val_loss: 0.2677 - val_accuracy: 0.8883\n",
      "Epoch 15/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.2538 - accuracy: 0.8917\n",
      "Epoch 15: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2562 - accuracy: 0.8911 - val_loss: 0.2756 - val_accuracy: 0.8596\n",
      "Epoch 16/50\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.3055 - accuracy: 0.8754\n",
      "Epoch 16: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.3054 - accuracy: 0.8754 - val_loss: 0.2902 - val_accuracy: 0.8596\n",
      "Epoch 17/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.2746 - accuracy: 0.8870\n",
      "Epoch 17: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2747 - accuracy: 0.8868 - val_loss: 0.6665 - val_accuracy: 0.7736\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.2817 - accuracy: 0.8822\n",
      "Epoch 18: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2817 - accuracy: 0.8822 - val_loss: 0.2786 - val_accuracy: 0.8825\n",
      "Epoch 19/50\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.2443 - accuracy: 0.8974\n",
      "Epoch 19: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2449 - accuracy: 0.8976 - val_loss: 0.2707 - val_accuracy: 0.8768\n",
      "Epoch 20/50\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.2390 - accuracy: 0.8974\n",
      "Epoch 20: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2408 - accuracy: 0.8972 - val_loss: 0.2954 - val_accuracy: 0.8424\n",
      "Epoch 21/50\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.2555 - accuracy: 0.8897\n",
      "Epoch 21: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2563 - accuracy: 0.8890 - val_loss: 0.2782 - val_accuracy: 0.8596\n",
      "Epoch 22/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.2403 - accuracy: 0.8943\n",
      "Epoch 22: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2400 - accuracy: 0.8947 - val_loss: 0.2995 - val_accuracy: 0.8711\n",
      "Epoch 23/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.2164 - accuracy: 0.8997\n",
      "Epoch 23: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2147 - accuracy: 0.9008 - val_loss: 0.3350 - val_accuracy: 0.8625\n",
      "Epoch 24/50\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.2563 - accuracy: 0.8923\n",
      "Epoch 24: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2582 - accuracy: 0.8918 - val_loss: 0.4238 - val_accuracy: 0.7966\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.9037\n",
      "Epoch 25: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2392 - accuracy: 0.9037 - val_loss: 0.2473 - val_accuracy: 0.8739\n",
      "Epoch 26/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.2059 - accuracy: 0.9153\n",
      "Epoch 26: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2048 - accuracy: 0.9158 - val_loss: 0.2636 - val_accuracy: 0.8711\n",
      "Epoch 27/50\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.2097 - accuracy: 0.9066\n",
      "Epoch 27: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2074 - accuracy: 0.9076 - val_loss: 0.3732 - val_accuracy: 0.8481\n",
      "Epoch 28/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.2113 - accuracy: 0.9190\n",
      "Epoch 28: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2144 - accuracy: 0.9165 - val_loss: 0.2841 - val_accuracy: 0.8711\n",
      "Epoch 29/50\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.2169 - accuracy: 0.9138\n",
      "Epoch 29: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2169 - accuracy: 0.9140 - val_loss: 0.3178 - val_accuracy: 0.8768\n",
      "Epoch 30/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.1916 - accuracy: 0.9270\n",
      "Epoch 30: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.1921 - accuracy: 0.9262 - val_loss: 0.4259 - val_accuracy: 0.8338\n",
      "Epoch 31/50\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.1842 - accuracy: 0.9243\n",
      "Epoch 31: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.1838 - accuracy: 0.9248 - val_loss: 0.3662 - val_accuracy: 0.8567\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.9144\n",
      "Epoch 32: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.2079 - accuracy: 0.9144 - val_loss: 0.2666 - val_accuracy: 0.8854\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.9262\n",
      "Epoch 33: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.1618 - accuracy: 0.9262 - val_loss: 0.3490 - val_accuracy: 0.8653\n",
      "Epoch 34/50\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.1600 - accuracy: 0.9335\n",
      "Epoch 34: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.1609 - accuracy: 0.9337 - val_loss: 0.4696 - val_accuracy: 0.8682\n",
      "Epoch 35/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.1496 - accuracy: 0.9419\n",
      "Epoch 35: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.1513 - accuracy: 0.9416 - val_loss: 0.4149 - val_accuracy: 0.8481\n",
      "Epoch 36/50\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.1389 - accuracy: 0.9415\n",
      "Epoch 36: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.1401 - accuracy: 0.9409 - val_loss: 0.3882 - val_accuracy: 0.8739\n",
      "Epoch 37/50\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.1476 - accuracy: 0.9411\n",
      "Epoch 37: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.1473 - accuracy: 0.9413 - val_loss: 0.4018 - val_accuracy: 0.8653\n",
      "Epoch 38/50\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.9490\n",
      "Epoch 38: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.1203 - accuracy: 0.9491 - val_loss: 0.5734 - val_accuracy: 0.8625\n",
      "Epoch 39/50\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.0951 - accuracy: 0.9618\n",
      "Epoch 39: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.0967 - accuracy: 0.9610 - val_loss: 0.5194 - val_accuracy: 0.8223\n",
      "Epoch 40/50\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.1040 - accuracy: 0.9596\n",
      "Epoch 40: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.1030 - accuracy: 0.9599 - val_loss: 0.5375 - val_accuracy: 0.8539\n",
      "Epoch 41/50\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.1770 - accuracy: 0.9400\n",
      "Epoch 41: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.1765 - accuracy: 0.9402 - val_loss: 0.6011 - val_accuracy: 0.8309\n",
      "Epoch 42/50\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.1243 - accuracy: 0.9537\n",
      "Epoch 42: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.1245 - accuracy: 0.9534 - val_loss: 0.7208 - val_accuracy: 0.8395\n",
      "Epoch 43/50\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9547\n",
      "Epoch 43: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.1082 - accuracy: 0.9549 - val_loss: 0.4443 - val_accuracy: 0.8711\n",
      "Epoch 44/50\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.0985 - accuracy: 0.9605\n",
      "Epoch 44: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.0985 - accuracy: 0.9606 - val_loss: 0.5735 - val_accuracy: 0.8510\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9696\n",
      "Epoch 45: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.0953 - accuracy: 0.9696 - val_loss: 0.5364 - val_accuracy: 0.8453\n",
      "Epoch 46/50\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 0.9616\n",
      "Epoch 46: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.1132 - accuracy: 0.9613 - val_loss: 0.7006 - val_accuracy: 0.8338\n",
      "Epoch 47/50\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.0977 - accuracy: 0.9643\n",
      "Epoch 47: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.0971 - accuracy: 0.9645 - val_loss: 0.5647 - val_accuracy: 0.8539\n",
      "Epoch 48/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.0590 - accuracy: 0.9786\n",
      "Epoch 48: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.0607 - accuracy: 0.9782 - val_loss: 0.6562 - val_accuracy: 0.8567\n",
      "Epoch 49/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9807\n",
      "Epoch 49: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.0563 - accuracy: 0.9803 - val_loss: 0.6652 - val_accuracy: 0.8653\n",
      "Epoch 50/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.0517 - accuracy: 0.9807\n",
      "Epoch 50: val_accuracy did not improve from 0.88825\n",
      "88/88 [==============================] - 2s 18ms/step - loss: 0.0512 - accuracy: 0.9810 - val_loss: 0.6104 - val_accuracy: 0.8797\n"
     ]
    }
   ],
   "source": [
    "# compile and fit the model to the data\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# save model plot\n",
    "plot_model(model, to_file='ENS.png')\n",
    "\n",
    "# start timer\n",
    "start = time.time()\n",
    "# fit the model\n",
    "history = model.fit (   X_train, y_train,\n",
    "                        epochs=EPOCHS,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        verbose=1,\n",
    "                        callbacks=callbacks,\n",
    "                        )\n",
    "# stop timer\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 6ms/step\n",
      "[ 0  4  9  9  9  1  9  4  9  6  4  9  5  9  4 11  7  9  6  6  2  7 10  6\n",
      " 10  0  0  5  9  4 11  9  9  4 10 11 11 11  7 11  4  1  7  1 10  4  9  9\n",
      "  9  9  1  0  4  0  6  0 11  4  2  9  6 10  7  4  2  0 11  0  6  4  9  6\n",
      "  6  9  9  5 10  7  8  4  8  4 10  5  9  1  1  0  7  0  9  4  1  2  9 10\n",
      " 10  9  9  4  6  7  5  1 11 11  5  9  0  9  8 10  9  9  4  5  1 10  9  1\n",
      "  5  4  7 11  1  4  0  9  1  2  9  4  1  4  1  6  3  4 11  5  2  6  3  9\n",
      "  9  1  0  4  9  9  3  4 10  2  1 11 10 10  5  9  7  9  4  5 10  9 10  6\n",
      "  9  1  5  7  5  2  7 10  4  9 10  1  9 11 11  7  6  3 10  3 10  2  6 11\n",
      "  6  9  1  2  1  9  9  0  9  1  1  9 11  9  7  0  6  4  4 10 10 10  7  0\n",
      "  9  4  0 11  5  1  7  7  4  5  9  3 10 11  9  4  6 10  1 10 10 10 11  9\n",
      " 11  3  9  7  1  4  3 10  9  6  0  0  4 10 11  6  9  6  8  9  9 11  7  9\n",
      " 11 10  4  4  9  9 10  7 11  4  6 11  5  9  4  9  6  9  0 10 11  4  2  4\n",
      "  3  9  4  6  4  6  9  6 10  4  5  9  2  9  1  9  1  9  1  9  9  7  9 10\n",
      "  7  1 11  9 10  7  1  6  9  4  9  9  6 10  0 11  1  6  7  1  9  3  4 10\n",
      "  9  9 10  6  5  6 10  4 10  4  1 10  6]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on our test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.rint(y_pred)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  AppleMusic     0.9048    0.9048    0.9048        21\n",
      "         Web     0.7576    0.8333    0.7937        30\n",
      "   Kinopoisk     1.0000    1.0000    1.0000        12\n",
      "LiveFacebook     1.0000    1.0000    1.0000        10\n",
      " LiveYouTube     0.8261    0.9744    0.8941        39\n",
      "     Netflix     0.9444    0.9444    0.9444        18\n",
      "  PrimeVideo     0.9375    1.0000    0.9677        30\n",
      "  SoundCloud     0.8750    0.9545    0.9130        22\n",
      "     Spotify     0.7500    0.5000    0.6000         6\n",
      "       Vimeo     0.9487    0.8043    0.8706        92\n",
      " YandexMusic     0.8333    0.8537    0.8434        41\n",
      "     YouTube     0.9655    1.0000    0.9825        28\n",
      "\n",
      "    accuracy                         0.8940       349\n",
      "   macro avg     0.8952    0.8975    0.8928       349\n",
      "weighted avg     0.8977    0.8940    0.8928       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models performance (I hope this isnt garbage)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8939828080229226\n",
      "Training Time: 86.00003409385681\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Training Time: \"+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Ensemble Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('ens_acc.jpg')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Ensemble Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('ens_loss.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
